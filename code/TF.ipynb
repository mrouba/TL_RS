{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578c1b80-5898-4f0a-b24b-4900a9968c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ffa28-3843-43aa-be99-898d1102a084",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42897ed9-dcb1-4a8f-bfce-c6cac53d6501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def data_preparation():\n",
    "    \n",
    "    data1 = pd.read_csv(\"path/to/data1.csv\")\n",
    "    data2 = pd.read_csv(\"path/to/data2.csv\")\n",
    "  \n",
    "    \n",
    "    print('data1', data1.shape)\n",
    "    print('data2', data2.shape)\n",
    "       \n",
    "    return data1 , data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd1407b9-8e01-4759-b2a7-afd03d8bce78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_df(df, train_size=0.8):\n",
    "    \"\"\"Splits a Pandas DataFrame into train and validation sets.\"\"\"\n",
    "    n = len(df)\n",
    "    \n",
    "    # shufling\n",
    "    df = df.sample(frac=1, random_state=0)\n",
    "    \n",
    "    split_index = int(n * train_size)\n",
    "    train_df = df.iloc[:split_index]\n",
    "    validation_df = df.iloc[split_index:]\n",
    "        \n",
    "    train_x = train_df.iloc[:, 0:8].to_numpy()\n",
    "    train_y = train_df.iloc[:, -1].to_numpy()\n",
    "    \n",
    "    validation_x = validation_df.iloc[:, 0:8].to_numpy()\n",
    "    validation_y = validation_df.iloc[:, -1].to_numpy()\n",
    "    \n",
    "    return train_x, validation_x, train_y, validation_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c455acb-024e-4836-9cb0-c2df64af00f6",
   "metadata": {},
   "source": [
    "# Data normalisation and EDA are Required (very importatne) .......................................................................\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c38742-249c-49d7-b525-f28d9df28455",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89fbebf-b99f-4c48-b88d-3ad706db7a99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 (10000, 10)\n",
      "data2 (10000, 10)\n",
      "x_train shape: (8000, 8) - y_train shape: (8000,)\n",
      "x_test shape: (2000, 8) - y_test shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Prepare the data\n",
    "\"\"\"\n",
    "#####################################################################\n",
    "data1 , data2 = data_preparation()\n",
    "#########################################################################\n",
    "# Select to source domaine !\n",
    "source_domain =  data1\n",
    "x_train, x_test, y_train, y_test = split_df(source_domain)\n",
    "#########################################################################\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf040bf-6b97-4584-b82c-69f0ab69db80",
   "metadata": {},
   "source": [
    "# Training binary classification on the source domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba35c16-866f-446e-8ab0-aa90a4a356cc",
   "metadata": {},
   "source": [
    "## Build the classification model (encoder model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea3fca15-0b41-4638-be42-3f81cd444485",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape  (8000, 8, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 8)                 17        \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 8)                 17000     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17017 (66.48 KB)\n",
      "Trainable params: 17000 (66.41 KB)\n",
      "Non-trainable params: 17 (72.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Using image data normalization layer ( can be used also for data augmentation)\n",
    "\"\"\"\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        # layers.RandomFlip(\"horizontal\"),\n",
    "        # layers.RandomRotation(0.02),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting the state of the normalization layer.\n",
    "data_augmentation.layers[0].adapt(x_train)\n",
    "\n",
    "##########################################################################################\n",
    "\"\"\"\n",
    "## Build the encoder model\n",
    "\n",
    "The encoder model takes the image as input and turns it into a 8-dimensional feature vector.\n",
    "\"\"\"\n",
    "\n",
    "# cnn model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout, Dense, Input\n",
    "\n",
    "\n",
    "num_classes = 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 128 \n",
    "hidden_units = 256\n",
    "projection_units = 32\n",
    "num_epochs = 100\n",
    "dropout_rate = 0.5\n",
    "temperature = 0.05\n",
    "n_features = 8\n",
    "verbose, epochs = 0, 50\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "print('x_train shape ', x_train.shape)\n",
    "\n",
    "########################################################################\n",
    "# # fit and evaluate a model\n",
    "def conv1D_model(trainX, trainy, testX, testy):\n",
    "    # verbose, epochs = 0, 10\n",
    "    n_features = trainX.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, \n",
    "                     kernel_size=3, \n",
    "                     activation='relu', \n",
    "                     input_shape=(n_features, 1)\n",
    "                    ))\n",
    "    model.add(Conv1D(filters=64, \n",
    "                     kernel_size=3, \n",
    "                     activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='relu')) \n",
    "    # model.summary()\n",
    "    return model\n",
    "  \n",
    "####################################################################\n",
    "def create_encoder():\n",
    "    \n",
    "    conv_model = conv1D_model(x_train, y_train, x_test, y_test)\n",
    "    inputs = keras.Input(shape=(n_features, ))\n",
    "    augmented = data_augmentation(inputs)\n",
    "    outputs   = conv_model(augmented)\n",
    "    model     = keras.Model(inputs=inputs, \n",
    "                        outputs=outputs, \n",
    "                        name=\"encoder\"\n",
    "                       )\n",
    "    return model\n",
    "\n",
    "######################################################################\n",
    "encoder = create_encoder()\n",
    "encoder.summary()\n",
    "######################################################################\n",
    "\n",
    "## Build the classification model\n",
    "\n",
    "def create_classifier(encoder, trainable=True):\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs   = keras.Input(shape=(n_features, ))\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(32, activation=\"relu\")(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"sigmoid\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"classifier\")\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy']\n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "515000bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 8)                 17017     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               2304      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27578 (107.73 KB)\n",
      "Trainable params: 27561 (107.66 KB)\n",
      "Non-trainable params: 17 (72.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder = create_encoder()\n",
    "classifier = create_classifier(encoder)\n",
    "classifier.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "564e09ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 8)                 17        \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 8)                 17000     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17017 (66.48 KB)\n",
      "Trainable params: 17000 (66.41 KB)\n",
      "Non-trainable params: 17 (72.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ea1229-c961-4a3a-b602-70be652e07a9",
   "metadata": {},
   "source": [
    "## Train the baseline classification model\n",
    "In this experiment, a baseline classifier is trained as usual, i.e., the\n",
    "encoder and the classifier parts are trained together as a single model\n",
    "to minimize the crossentropy loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06d56e6b-a891-43bd-81b6-20a809ff563b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 8)                 17017     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               2304      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                8224      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27578 (107.73 KB)\n",
      "Trainable params: 27561 (107.66 KB)\n",
      "Non-trainable params: 17 (72.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.4526 - accuracy: 0.7979\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1264 - accuracy: 0.9582\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9786\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9841\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9868\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9891\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9875\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9916\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9896\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9904\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9919\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 0.9929\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9916\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.9918\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.9944\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9929\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9934\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9945\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9948\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9948\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9939\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9942\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9954\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9936\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9945\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9939\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9950\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9959\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9951\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9945\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9940\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9961\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9945\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9958\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9956\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9951\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9959\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9959\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9955\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9960\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9966\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9964\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9964\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9964\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9962\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9964\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9954\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9964\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9975\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9966\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9956\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9961\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9960\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9965\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9980\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9973\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9962\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9969\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9967\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9949\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9960\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9970\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9962\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9974\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9967\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9960\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9969\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9962\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9974\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9973\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9965\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9974\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9964\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9977\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9977\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9976\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9964\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9975\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9983\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9971\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9965\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9977\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9966\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9969\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9976\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9976\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9977\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9979\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9969\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9976\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9977\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9971\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9970\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9975\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.0088 - accuracy: 0.9970\n",
      "Test accuracy: 99.7%\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder()\n",
    "classifier = create_classifier(encoder)\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "history = classifier.fit(x=x_train, \n",
    "                         y=y_train, \n",
    "                         batch_size=batch_size, \n",
    "                         epochs=num_epochs\n",
    "                        )\n",
    "\n",
    "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9ab90e-5ade-4022-a0d6-a847ef3b7a0b",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64817d72-26fb-48e9-ad4b-c5a745078c73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (10, 8)\n",
      "x_test.shape : (9990, 8)\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.7056 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7342 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5698 - accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5123 - accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.7000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.9000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2847 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3025 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2653 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2311 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2135 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2174 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2208 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1641 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1810 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1679 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1111 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1114 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1296 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0687 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0585 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0282 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "313/313 [==============================] - 0s 782us/step - loss: 0.0473 - accuracy: 0.9821\n",
      "Test accuracy: 98.21%\n"
     ]
    }
   ],
   "source": [
    "# Select the target domain \n",
    "# shufling and select a small dataset\n",
    "target_domain = data2\n",
    "target_domain = target_domain.sample(frac=1, random_state=0)\n",
    "\n",
    "# Select the desired train_size\n",
    "x_train, x_test, y_train, y_test = split_df(target_domain, \n",
    "                                            train_size=0.001\n",
    "                                           )\n",
    "#########################################################################\n",
    "print('x_train.shape :', x_train.shape)\n",
    "print('x_test.shape :', x_test.shape)\n",
    "#########################################################################\n",
    "\n",
    "## Train the classifier with the frozen encoder\n",
    "classifier = create_classifier(encoder, \n",
    "                               trainable=False\n",
    "                              )\n",
    "\n",
    "history = classifier.fit(x=x_train, \n",
    "                         y=y_train, \n",
    "                         batch_size=batch_size, \n",
    "                         epochs=num_epochs\n",
    "                        )\n",
    "\n",
    "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06cad70e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 859us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred=classifier.predict(x_test,batch_size=batch_size)\n",
    "y_pred = np.squeeze(y_pred)\n",
    "y_pred = np.where(y_pred < 0.5, 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd9155f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      4995\n",
      "         1.0       0.97      0.99      0.98      4995\n",
      "\n",
      "    accuracy                           0.98      9990\n",
      "   macro avg       0.98      0.98      0.98      9990\n",
      "weighted avg       0.98      0.98      0.98      9990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406a250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3e802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb04887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
